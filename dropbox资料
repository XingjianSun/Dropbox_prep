
Lc 609 find duplicate files
Space Panorama =>LRU double linked list/ dictionary with remove and add
LC 379

Duplicate files
Import md5
M = md5.new()
m.update(string)
m.digest()

https://paper.dropbox.com/doc/Interview-Notes-Dropbox-wl7npLjRBjrAKA5AOBsaM

CAP theorem:
Consistency, availability, partition fault tolerance


Microservice Architectureï¼Ÿ


find duplicate files:
1. Checkpoints? Save states from time to time
2. Md5 for hash, time consuming
3. Cycle?


Usually hashes wouldn't do sums, otherwise stop and pots will have the same hash.

and you wouldn't limit it to the first n characters because otherwise house and houses would have the same hash.

Generally hashs take values and multiply it by a prime number (makes it more likely to generate unique hashes) So you could do something like:

int hash = 7;
for (int i = 0; i < strlen; i++) {
    hash = hash*31 + charAt(i);
}
